{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe9934a",
   "metadata": {},
   "source": [
    "## ğŸš€ ë¯¸ì…˜: â€œë‰´ìŠ¤ í† í”½ ë¶„ë¥˜ & ì–¸ì–´ ëª¨ë¸ ì‹¤ìŠµâ€\n",
    "\n",
    "### ë°°ê²½ ìŠ¤í† ë¦¬  \n",
    "ì—¬ëŸ¬ë¶„ì€ ë¯¸ë””ì–´ ë¶„ì„íŒ€ì˜ ì‹ ì… NLP AI SW ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.  \n",
    "ë§¤ì¼ ìŸì•„ì§€ëŠ” ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ **ì •ì¹˜**, **ê²½ì œ**, **ìŠ¤í¬ì¸ **, **ê¸°ìˆ **, ê¸°íƒ€ ë“± 5ê°€ì§€ ì¹´í…Œê³ ë¦¬ë¡œ ìë™ ë¶„ë¥˜í•˜ê³ , ë™ì‹œì— ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì–¸ì–´ëª¨ë¸ì„ ì—°êµ¬í•˜ê¸° ìœ„í•´ â€œë‹¤ìŒ ë‹¨ì–´â€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” **ì–¸ì–´ ëª¨ë¸**ì„ êµ¬ì¶•í•´ì•¼ í•©ë‹ˆë‹¤.  \n",
    "\n",
    "---\n",
    "\n",
    "### ë¬¸ì œ 1. ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬  \n",
    "1. **ë°ì´í„°ì…‹**:\n",
    "BBC articles fulltext and category\n",
    "https://www.kaggle.com/datasets/yufengdev/bbc-fulltext-and-category?resource=download\n",
    "\n",
    "2. **Tokenization**: `Tokenizer`ë¥¼ ì´ìš©í•´ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ê³ , `pad_sequences`ë¡œ ê¸¸ì´ 200ìœ¼ë¡œ íŒ¨ë”©.  \n",
    "3. **í›ˆë ¨/ê²€ì¦ ë¶„í• **: í›ˆë ¨ ë°ì´í„°ë¥¼ 80%/20%ë¡œ ë‚˜ëˆ„ê¸°.  \n",
    "\n",
    "> **ì¶œë ¥**:  \n",
    "> - ë‹¨ì–´ ì§‘í•© í¬ê¸°(`num_words`)  \n",
    "> - íŒ¨ë”© í›„ ì‹œí€€ìŠ¤ í˜•íƒœ  \n",
    "> - í›ˆë ¨/ê²€ì¦ ìƒ˜í”Œ ê°œìˆ˜  \n",
    "\n",
    "---\n",
    "\n",
    "### ë¬¸ì œ 2. ëœë¤ ì´ˆê¸°í™” ì„ë² ë”©ì„ ì´ìš©í•œ í…ìŠ¤íŠ¸ ë¶„ë¥˜  \n",
    "1. **ëª¨ë¸ êµ¬ì¡°**:  \n",
    "   - `Embedding(input_dim=num_words, output_dim=100, input_length=200)`  \n",
    "   - `GlobalAveragePooling1D()`  \n",
    "   - `Dense(64, activation='relu')`  \n",
    "   - `Dense(4, activation='softmax')`  \n",
    "2. **í•™ìŠµ ì„¤ì •**:  \n",
    "   - ì˜µí‹°ë§ˆì´ì €: Adam  \n",
    "   - ì†ì‹¤í•¨ìˆ˜: sparse categorical crossentropy  \n",
    "   - í‰ê°€ ì§€í‘œ: accuracy  \n",
    "   - ì—í¬í¬: 10, ë°°ì¹˜ì‚¬ì´ì¦ˆ: 32  \n",
    "3. **ê²°ê³¼ ê¸°ë¡**:  \n",
    "   - í›ˆë ¨/ê²€ì¦ ì •í™•ë„ ë° ì†ì‹¤ í”Œë¡¯  \n",
    "\n",
    "> **ì§ˆë¬¸**: ëœë¤ ì´ˆê¸°í™” ì„ë² ë”©ë§Œìœ¼ë¡œ ë¶„ë¥˜ ì„±ëŠ¥ì´ ì–´ëŠ ì •ë„ ë‚˜ì˜¤ëŠ”ê°€?\n",
    "\n",
    "---\n",
    "\n",
    "### ë¬¸ì œ 3. ì‚¬ì „ í•™ìŠµëœ ì›Œë“œ ì„ë² ë”© ì ìš©  \n",
    "1. **ì‚¬ì „ í•™ìŠµ ì„ë² ë”©**: GloVe 100d (`glove.6B.100d.txt`) ì‚¬ìš©  \n",
    "2. **ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±**:  \n",
    "   - ë‹¨ì–´ ì¸ë±ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ GloVe ë²¡í„° ë§¤í•‘  \n",
    "   - OOV ë‹¨ì–´ëŠ” ëœë¤ ì´ˆê¸°í™”  \n",
    "3. **Embedding ë ˆì´ì–´**: `trainable=False`ë¡œ ê³ ì •  \n",
    "4. **ëª¨ë¸**: ë¬¸ì œ 2ì™€ ë™ì¼í•œ êµ¬ì¡°  \n",
    "5. **í•™ìŠµ ë° í‰ê°€**:  \n",
    "   - ì—í¬í¬ 10, ë°°ì¹˜ì‚¬ì´ì¦ˆ 32  \n",
    "   - í›ˆë ¨/ê²€ì¦ ì •í™•ë„ ë¹„êµ  \n",
    "\n",
    "> **ì§ˆë¬¸**: ëœë¤ ì´ˆê¸°í™” ì„ë² ë”© ëŒ€ë¹„ ì„±ëŠ¥ ì°¨ì´ëŠ”?\n",
    "\n",
    "---\n",
    "\n",
    "### ë¬¸ì œ 4. ì‹ ê²½ë§ ì–¸ì–´ ëª¨ë¸(Neural Language Model)  \n",
    "1. **ë°ì´í„° ìƒì„±**:  \n",
    "   - ì „ì²˜ë¦¬ëœ ë‰´ìŠ¤ ê¸°ì‚¬ ì‹œí€€ìŠ¤ì—ì„œ ìœˆë„ìš° í¬ê¸° 5ë¡œ ìŠ¬ë¼ì´ë”©  \n",
    "   - (ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´=4, ì •ë‹µ=5ë²ˆì§¸ ë‹¨ì–´) ìŒ ìƒì„±  \n",
    "2. **ëª¨ë¸ êµ¬ì¡°**:  \n",
    "   ==> íŒŒì´í† ì¹˜ ëª¨ë¸ë¡œ ë³€ê²½í•´ì„œ êµ¬í˜„\n",
    "   - `Embedding(num_words, 100, input_length=4)`  \n",
    "   - `Flatten()`  \n",
    "   - `Dense(64, activation='relu')`  \n",
    "   - `Dense(num_words, activation='softmax')`\n",
    "   \n",
    "3. **í•™ìŠµ ì„¤ì •**:  \n",
    "   - ì†ì‹¤í•¨ìˆ˜: categorical crossentropy  \n",
    "   - ì—í¬í¬: 5, ë°°ì¹˜: 128  \n",
    "4. **ê²°ê³¼ ê¸°ë¡**:  \n",
    "   - í›ˆë ¨ ì†ì‹¤ ë° ì •í™•ë„  \n",
    "\n",
    "> **ì§ˆë¬¸**: ê°„ë‹¨í•œ ì‹ ê²½ë§ ì–¸ì–´ ëª¨ë¸ì´ â€œë‹¤ìŒ ë‹¨ì–´â€ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì˜ˆì¸¡í•˜ëŠ”ê°€?\n",
    "\n",
    "---\n",
    "\n",
    "### ë¬¸ì œ 5. ì„ë² ë”© ë²¡í„° ì‹œê°í™”  \n",
    "1. ë¬¸ì œ 3ì—ì„œ ìƒì„±í•œ **ì‚¬ì „ í•™ìŠµ ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤** ì¤‘  \n",
    "   - ìƒìœ„ ë¹ˆë„ 200ê°œ ë‹¨ì–´ ë²¡í„° ì¶”ì¶œ  \n",
    "2. **ì°¨ì› ì¶•ì†Œ**: TSNE ë˜ëŠ” PCAë¡œ 2ì°¨ì› ë³€í™˜  \n",
    "3. **ì‹œê°í™”**: matplotlib ì‚°ì ë„ë¡œ ì£¼ìš” ë‹¨ì–´(ì˜ˆ: â€˜governmentâ€™, â€˜marketâ€™, â€˜teamâ€™, â€˜technologyâ€™ ë“±) ë¼ë²¨ë§  \n",
    "\n",
    "> **ì§ˆë¬¸**: ì„œë¡œ ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ ë‹¨ì–´ë“¤ì€ 2D ê³µê°„ì—ì„œ ì–´ë–»ê²Œ êµ°ì§‘ë˜ëŠ”ê°€?\n",
    "\n",
    "---\n",
    "\n",
    "### ì œì¶œ í˜•ì‹  \n",
    "- í•˜ë‚˜ì˜ Jupyter Notebook(.ipynb)  \n",
    "- ê° ë¬¸ì œë§ˆë‹¤ ì½”ë“œ, ì‹¤í–‰ ê²°ê³¼(ìˆ«ìÂ·ê·¸ë˜í”„), ê°„ë‹¨í•œ í•´ì„¤(1â€“2ë¬¸ì¥) í¬í•¨  \n",
    "- ë°ì´í„° ë‹¤ìš´ë¡œë“œ(GloVe ë“±)ëŠ” ì½”ë“œ ì…€ì— ì£¼ì„ìœ¼ë¡œ ë§í¬ë§Œ ë‚¨ê¸°ê³  ì‹¤ì œ ë‹¤ìš´ë¡œë“œëŠ” ìˆ˜ë™ìœ¼ë¡œ ìˆ˜í–‰í•´ë„ ë¬´ë°©  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be97959f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "import pandas as pd\n",
    "\n",
    "original_df = pd.read_csv(\"bbc-text.csv\")\n",
    "original_df\n",
    "\n",
    "df = original_df.copy()\n",
    "df.head(5)  # ì²˜ìŒ 5ê°œ í–‰ì„ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d55ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  tv future in the hands of viewers with home th...\n",
       "1  worldcom boss  left books alone  former worldc...\n",
       "2  tigers wary of farrell  gamble  leicester say ...\n",
       "3  yeading face newcastle in fa cup premiership s...\n",
       "4  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"category\"])  # \"category\" ì—´ ì‚­ì œ\n",
    "df.head(5)  # ì²˜ìŒ 5ê°œ í–‰ì„ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "512f8d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\wjdgn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tv, future, in, the, hands, of, viewers, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[worldcom, boss, left, books, alone, former, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tigers, wary, of, farrell, gamble, leicester,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[yeading, face, newcastle, in, fa, cup, premie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ocean, s, twelve, raids, box, office, ocean, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [tv, future, in, the, hands, of, viewers, with...\n",
       "1  [worldcom, boss, left, books, alone, former, w...\n",
       "2  [tigers, wary, of, farrell, gamble, leicester,...\n",
       "3  [yeading, face, newcastle, in, fa, cup, premie...\n",
       "4  [ocean, s, twelve, raids, box, office, ocean, ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í† í°í™”\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")  # punkt íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "df[\"text\"] = df[\"text\"].apply(word_tokenize)  # \"text\" ì—´ì— ëŒ€í•´ í† í°í™”\n",
    "df.head(5)  # ì²˜ìŒ 5ê°œ í–‰ì„ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7b6b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¨ì–´ ì§‘í•© í¬ê¸°: 29726\n",
      "íŒ¨ë”© í›„ ì‹œí€€ìŠ¤ shape: (2225, 200)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„\n",
    "texts = df[\"text\"].apply(lambda x: \" \".join(x)).tolist()\n",
    "\n",
    "# í† í¬ë‚˜ì´ì € ìƒì„± ë° ì‹œí€€ìŠ¤ ë³€í™˜\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# pad_sequences ì ìš© (ê¸¸ì´ 200)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=200, padding='post', truncating='post')\n",
    "\n",
    "# ë‹¨ì–´ ì§‘í•© í¬ê¸°\n",
    "num_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(\"ë‹¨ì–´ ì§‘í•© í¬ê¸°:\", num_words)\n",
    "print(\"íŒ¨ë”© í›„ ì‹œí€€ìŠ¤ shape:\", padded_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf30d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í›ˆë ¨ ìƒ˜í”Œ ê°œìˆ˜: 1780\n",
      "ê²€ì¦ ìƒ˜í”Œ ê°œìˆ˜: 445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# í›ˆë ¨/ê²€ì¦ ë¶„í•  (80/20)\n",
    "X_train, X_val = train_test_split(padded_sequences, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"í›ˆë ¨ ìƒ˜í”Œ ê°œìˆ˜:\", len(X_train))\n",
    "print(\"ê²€ì¦ ìƒ˜í”Œ ê°œìˆ˜:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ade661f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wjdgn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     14\u001b[39m model.compile(\n\u001b[32m     15\u001b[39m     optimizer=Adam(),\n\u001b[32m     16\u001b[39m     loss=\u001b[33m'\u001b[39m\u001b[33msparse_categorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     17\u001b[39m     metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ëª¨ë¸ í•™ìŠµ\u001b[39;00m\n\u001b[32m     21\u001b[39m history = model.fit(\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     X_train, \u001b[43my_train\u001b[49m,\n\u001b[32m     23\u001b[39m     validation_data=(X_val, y_val),\n\u001b[32m     24\u001b[39m     epochs=\u001b[32m10\u001b[39m,\n\u001b[32m     25\u001b[39m     batch_size=\u001b[32m32\u001b[39m\n\u001b[32m     26\u001b[39m )\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# í›ˆë ¨/ê²€ì¦ ì •í™•ë„ ë° ì†ì‹¤ í”Œë¡¯\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ëª¨ë¸ ì •ì˜\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=100, input_length=200),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(5, activation='softmax')  # 5ê°œ ì¹´í…Œê³ ë¦¬ (category_to_index ì°¸ê³ )\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# í›ˆë ¨/ê²€ì¦ ì •í™•ë„ ë° ì†ì‹¤ í”Œë¡¯\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.plot(history.history['loss'], label='Train Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896f532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëœë¤ ì´ˆê¸°í™” ì„ë² ë”© ëª¨ë¸ì˜ ìµœì¢… í›ˆë ¨ ì •í™•ë„: 0.9326\n",
      "ëœë¤ ì´ˆê¸°í™” ì„ë² ë”© ëª¨ë¸ì˜ ìµœì¢… ê²€ì¦ ì •í™•ë„: 0.1775\n"
     ]
    }
   ],
   "source": [
    "# í›ˆë ¨/ê²€ì¦ ì •í™•ë„ í™•ì¸\n",
    "train_acc = history.history['accuracy'][-1]\n",
    "val_acc = history.history['val_accuracy'][-1]\n",
    "\n",
    "print(f\"ëœë¤ ì´ˆê¸°í™” ì„ë² ë”© ëª¨ë¸ì˜ ìµœì¢… í›ˆë ¨ ì •í™•ë„: {train_acc:.4f}\")\n",
    "print(f\"ëœë¤ ì´ˆê¸°í™” ì„ë² ë”© ëª¨ë¸ì˜ ìµœì¢… ê²€ì¦ ì •í™•ë„: {val_acc:.4f}\")\n",
    "\n",
    "# ê°„ë‹¨ í•´ì„¤\n",
    "# ëœë¤ ì´ˆê¸°í™” ì„ë² ë”©ë§Œìœ¼ë¡œë„ ì•½ {val_acc:.2%}ì˜ ê²€ì¦ ì •í™•ë„ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.\n",
    "# ì´ëŠ” ì„ë² ë”©ì´ í•™ìŠµ ê³¼ì •ì—ì„œ ì˜ë¯¸ ìˆëŠ” í‘œí˜„ì„ ì¼ë¶€ í•™ìŠµí•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d259a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
