{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe9934a",
   "metadata": {},
   "source": [
    "## 🚀 미션: “뉴스 토픽 분류 & 언어 모델 실습”\n",
    "\n",
    "### 배경 스토리  \n",
    "여러분은 미디어 분석팀의 신입 NLP AI SW 엔지니어입니다.  \n",
    "매일 쏟아지는 뉴스 기사를 **정치**, **경제**, **스포츠**, **기술**, 기타 등 5가지 카테고리로 자동 분류하고, 동시에 뉴스 기사의 언어모델을 연구하기 위해 “다음 단어”를 예측하는 **언어 모델**을 구축해야 합니다.  \n",
    "\n",
    "---\n",
    "\n",
    "### 문제 1. 데이터 준비 및 전처리  \n",
    "1. **데이터셋**:\n",
    "BBC articles fulltext and category\n",
    "https://www.kaggle.com/datasets/yufengdev/bbc-fulltext-and-category?resource=download\n",
    "\n",
    "2. **Tokenization**: `Tokenizer`를 이용해 시퀀스로 변환하고, `pad_sequences`로 길이 200으로 패딩.  \n",
    "3. **훈련/검증 분할**: 훈련 데이터를 80%/20%로 나누기.  \n",
    "\n",
    "> **출력**:  \n",
    "> - 단어 집합 크기(`num_words`)  \n",
    "> - 패딩 후 시퀀스 형태  \n",
    "> - 훈련/검증 샘플 개수  \n",
    "\n",
    "---\n",
    "\n",
    "### 문제 2. 랜덤 초기화 임베딩을 이용한 텍스트 분류  \n",
    "1. **모델 구조**:  \n",
    "   - `Embedding(input_dim=num_words, output_dim=100, input_length=200)`  \n",
    "   - `GlobalAveragePooling1D()`  \n",
    "   - `Dense(64, activation='relu')`  \n",
    "   - `Dense(4, activation='softmax')`  \n",
    "2. **학습 설정**:  \n",
    "   - 옵티마이저: Adam  \n",
    "   - 손실함수: sparse categorical crossentropy  \n",
    "   - 평가 지표: accuracy  \n",
    "   - 에포크: 10, 배치사이즈: 32  \n",
    "3. **결과 기록**:  \n",
    "   - 훈련/검증 정확도 및 손실 플롯  \n",
    "\n",
    "> **질문**: 랜덤 초기화 임베딩만으로 분류 성능이 어느 정도 나오는가?\n",
    "\n",
    "---\n",
    "\n",
    "### 문제 3. 사전 학습된 워드 임베딩 적용  \n",
    "1. **사전 학습 임베딩**: GloVe 100d (`glove.6B.100d.txt`) 사용  \n",
    "2. **임베딩 매트릭스 생성**:  \n",
    "   - 단어 인덱스 기반으로 GloVe 벡터 매핑  \n",
    "   - OOV 단어는 랜덤 초기화  \n",
    "3. **Embedding 레이어**: `trainable=False`로 고정  \n",
    "4. **모델**: 문제 2와 동일한 구조  \n",
    "5. **학습 및 평가**:  \n",
    "   - 에포크 10, 배치사이즈 32  \n",
    "   - 훈련/검증 정확도 비교  \n",
    "\n",
    "> **질문**: 랜덤 초기화 임베딩 대비 성능 차이는?\n",
    "\n",
    "---\n",
    "\n",
    "### 문제 4. 신경망 언어 모델(Neural Language Model)  \n",
    "1. **데이터 생성**:  \n",
    "   - 전처리된 뉴스 기사 시퀀스에서 윈도우 크기 5로 슬라이딩  \n",
    "   - (입력 시퀀스 길이=4, 정답=5번째 단어) 쌍 생성  \n",
    "2. **모델 구조**:  \n",
    "   ==> 파이토치 모델로 변경해서 구현\n",
    "   - `Embedding(num_words, 100, input_length=4)`  \n",
    "   - `Flatten()`  \n",
    "   - `Dense(64, activation='relu')`  \n",
    "   - `Dense(num_words, activation='softmax')`\n",
    "   \n",
    "3. **학습 설정**:  \n",
    "   - 손실함수: categorical crossentropy  \n",
    "   - 에포크: 5, 배치: 128  \n",
    "4. **결과 기록**:  \n",
    "   - 훈련 손실 및 정확도  \n",
    "\n",
    "> **질문**: 간단한 신경망 언어 모델이 “다음 단어”를 얼마나 잘 예측하는가?\n",
    "\n",
    "---\n",
    "\n",
    "### 문제 5. 임베딩 벡터 시각화  \n",
    "1. 문제 3에서 생성한 **사전 학습 임베딩 매트릭스** 중  \n",
    "   - 상위 빈도 200개 단어 벡터 추출  \n",
    "2. **차원 축소**: TSNE 또는 PCA로 2차원 변환  \n",
    "3. **시각화**: matplotlib 산점도로 주요 단어(예: ‘government’, ‘market’, ‘team’, ‘technology’ 등) 라벨링  \n",
    "\n",
    "> **질문**: 서로 의미가 비슷한 단어들은 2D 공간에서 어떻게 군집되는가?\n",
    "\n",
    "---\n",
    "\n",
    "### 제출 형식  \n",
    "- 하나의 Jupyter Notebook(.ipynb)  \n",
    "- 각 문제마다 코드, 실행 결과(숫자·그래프), 간단한 해설(1–2문장) 포함  \n",
    "- 데이터 다운로드(GloVe 등)는 코드 셀에 주석으로 링크만 남기고 실제 다운로드는 수동으로 수행해도 무방  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be97959f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "import pandas as pd\n",
    "\n",
    "original_df = pd.read_csv(\"bbc-text.csv\")\n",
    "original_df\n",
    "\n",
    "df = original_df.copy()\n",
    "df.head(5)  # 처음 5개 행을 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d55ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  tv future in the hands of viewers with home th...\n",
       "1  worldcom boss  left books alone  former worldc...\n",
       "2  tigers wary of farrell  gamble  leicester say ...\n",
       "3  yeading face newcastle in fa cup premiership s...\n",
       "4  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"category\"])  # \"category\" 열 삭제\n",
    "df.head(5)  # 처음 5개 행을 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "512f8d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\wjdgn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tv, future, in, the, hands, of, viewers, with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[worldcom, boss, left, books, alone, former, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tigers, wary, of, farrell, gamble, leicester,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[yeading, face, newcastle, in, fa, cup, premie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ocean, s, twelve, raids, box, office, ocean, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [tv, future, in, the, hands, of, viewers, with...\n",
       "1  [worldcom, boss, left, books, alone, former, w...\n",
       "2  [tigers, wary, of, farrell, gamble, leicester,...\n",
       "3  [yeading, face, newcastle, in, fa, cup, premie...\n",
       "4  [ocean, s, twelve, raids, box, office, ocean, ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰화\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")  # punkt 패키지 다운로드\n",
    "df[\"text\"] = df[\"text\"].apply(word_tokenize)  # \"text\" 열에 대해 토큰화\n",
    "df.head(5)  # 처음 5개 행을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7b6b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합 크기: 29726\n",
      "패딩 후 시퀀스 shape: (2225, 200)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 텍스트 데이터 준비\n",
    "texts = df[\"text\"].apply(lambda x: \" \".join(x)).tolist()\n",
    "\n",
    "# 토크나이저 생성 및 시퀀스 변환\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# pad_sequences 적용 (길이 200)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=200, padding='post', truncating='post')\n",
    "\n",
    "# 단어 집합 크기\n",
    "num_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(\"단어 집합 크기:\", num_words)\n",
    "print(\"패딩 후 시퀀스 shape:\", padded_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf30d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 1780\n",
      "검증 샘플 개수: 445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# 훈련/검증 분할 (80/20)\n",
    "X_train, X_val = train_test_split(padded_sequences, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"훈련 샘플 개수:\", len(X_train))\n",
    "print(\"검증 샘플 개수:\", len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ade661f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wjdgn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     14\u001b[39m model.compile(\n\u001b[32m     15\u001b[39m     optimizer=Adam(),\n\u001b[32m     16\u001b[39m     loss=\u001b[33m'\u001b[39m\u001b[33msparse_categorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     17\u001b[39m     metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[32m     21\u001b[39m history = model.fit(\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     X_train, \u001b[43my_train\u001b[49m,\n\u001b[32m     23\u001b[39m     validation_data=(X_val, y_val),\n\u001b[32m     24\u001b[39m     epochs=\u001b[32m10\u001b[39m,\n\u001b[32m     25\u001b[39m     batch_size=\u001b[32m32\u001b[39m\n\u001b[32m     26\u001b[39m )\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# 훈련/검증 정확도 및 손실 플롯\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델 정의\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=num_words, output_dim=100, input_length=200),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(5, activation='softmax')  # 5개 카테고리 (category_to_index 참고)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# 훈련/검증 정확도 및 손실 플롯\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.plot(history.history['loss'], label='Train Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896f532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 초기화 임베딩 모델의 최종 훈련 정확도: 0.9326\n",
      "랜덤 초기화 임베딩 모델의 최종 검증 정확도: 0.1775\n"
     ]
    }
   ],
   "source": [
    "# 훈련/검증 정확도 확인\n",
    "train_acc = history.history['accuracy'][-1]\n",
    "val_acc = history.history['val_accuracy'][-1]\n",
    "\n",
    "print(f\"랜덤 초기화 임베딩 모델의 최종 훈련 정확도: {train_acc:.4f}\")\n",
    "print(f\"랜덤 초기화 임베딩 모델의 최종 검증 정확도: {val_acc:.4f}\")\n",
    "\n",
    "# 간단 해설\n",
    "# 랜덤 초기화 임베딩만으로도 약 {val_acc:.2%}의 검증 정확도를 달성했습니다.\n",
    "# 이는 임베딩이 학습 과정에서 의미 있는 표현을 일부 학습할 수 있음을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d259a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
