{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e5750f",
   "metadata": {},
   "source": [
    "\n",
    "# 초급 딥러닝 미션: \"인공지능 마법사의 첫 번째 신경망\"\n",
    "\n",
    "## 🎯 학습 목표\n",
    "- 딥러닝 및 파이토치 기본 개념 이해\n",
    "- 텐서 생성 및 조작\n",
    "- `nn.Module` 기반 모델 작성\n",
    "- 시퀀셜 모델 구성\n",
    "- 손실함수, 옵티마이저, 학습 루프 직접 구현\n",
    "- 정확도 등 메트릭 계산 및 시각화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56453caf",
   "metadata": {},
   "source": [
    "\n",
    "## 📂 사용 데이터셋\n",
    "**MNIST 손글씨 숫자 이미지** (10개 숫자 분류, 흑백 이미지)  \n",
    "👉 `torchvision.datasets.MNIST`에서 자동 다운로드 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f8d07",
   "metadata": {},
   "source": [
    "\n",
    "## 🧩 미션 구성\n",
    "\n",
    "### Part 1. 딥러닝과 파이토치 개요  \n",
    "❓ 문제 1  \n",
    "**딥러닝이 머신러닝과 다른 점은 무엇인가요?**  \n",
    "✔️ 정답: 특징 추출과 분류를 동시에 자동 학습 가능하다.\n",
    "\n",
    "❓ 문제 2  \n",
    "**파이토치의 핵심 구성 요소 3가지를 쓰세요.**  \n",
    "✔️ 정답: Tensor, Autograd, Module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5b2f78",
   "metadata": {},
   "source": [
    "\n",
    "### Part 2. 텐서 연산 실습  \n",
    "🔧 실습 문제 3  \n",
    "아래 조건에 맞는 텐서를 생성하세요:  \n",
    "- 3x3 크기의 정규분포 난수 텐서\n",
    "- 모든 원소에 대해 ReLU 함수를 적용한 텐서\n",
    "\n",
    "힌트: `torch.randn`, `torch.relu`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "622f5f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f9ebc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6923,  0.2355,  0.8030],\n",
      "        [ 0.1868,  1.4079,  0.1135],\n",
      "        [ 1.2457,  0.5788, -1.4053]])\n",
      "tensor([[0.0000, 0.2355, 0.8030],\n",
      "        [0.1868, 1.4079, 0.1135],\n",
      "        [1.2457, 0.5788, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 3x3 tensor with random values from a normal distribution\n",
    "tensor = torch.randn(3, 3)\n",
    "print(tensor)\n",
    "\n",
    "tensor_relu = torch.relu(tensor)\n",
    "print(tensor_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82769594",
   "metadata": {},
   "source": [
    "\n",
    "### Part 3. 신경망 직접 만들기  \n",
    "🔧 실습 문제 4  \n",
    "다음과 같은 신경망을 `nn.Module` 클래스를 상속받아 구현하세요:\n",
    "\n",
    "- 입력: 28×28 이미지 → 784차원\n",
    "- 은닉층: 128개 뉴런, 활성화 함수 ReLU\n",
    "- 출력층: 10개 뉴런, 소프트맥스\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97300a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)   \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39110a28",
   "metadata": {},
   "source": [
    "\n",
    "### Part 4. 시퀀셜 모델 구성  \n",
    "🔧 실습 문제 5  \n",
    "동일한 구조를 `nn.Sequential`을 사용하여 작성하세요.\n",
    "\n",
    "힌트: `nn.Sequential(...)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff07bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e808a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d895ff92",
   "metadata": {},
   "source": [
    "### Part 5. 손실함수와 옵티마이저  \n",
    "🔧 실습 문제 6  \n",
    "다음 코드에서 손실함수와 옵티마이저를 정의하세요:\n",
    "\n",
    "```python\n",
    "model = MyNet()\n",
    "# 손실 함수 정의\n",
    "# 옵티마이저 정의\n",
    "```\n",
    "\n",
    "요구사항:\n",
    "- 손실 함수: `CrossEntropyLoss`\n",
    "- 옵티마이저: `SGD`, 학습률 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c253848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = MyNet()\n",
    "\n",
    "# 손실 함수 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 정의\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda4b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(criterion)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b400a00",
   "metadata": {},
   "source": [
    "\n",
    "### Part 6. 데이터셋 및 데이터로더  \n",
    "🔧 실습 문제 7  \n",
    "`torchvision.datasets.MNIST`를 사용하여 학습 및 검증 데이터를 불러오고, `DataLoader`를 사용하여 배치 사이즈 64로 나누세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "664343fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a22e83",
   "metadata": {},
   "source": [
    "\n",
    "### Part 7. 학습 루프 구현하기  \n",
    "🔧 실습 문제 8  \n",
    "기본적인 학습 루프를 구현하세요. 다음을 포함해야 합니다:\n",
    "- 배치 단위 데이터 가져오기\n",
    "- 예측값 계산 (`model(x)`)\n",
    "- 손실 계산 및 역전파\n",
    "- 파라미터 업데이트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd5711b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 완료\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "        output = model(images)  # 모델에 입력\n",
    "        loss = criterion(output, labels)  # 손실 계산\n",
    "        loss.backward()  # 역전파\n",
    "        optimizer.step()  # 가중치 업데이트\n",
    "    print(f'Epoch {epoch+1} 완료')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19afcdd",
   "metadata": {},
   "source": [
    "\n",
    "### Part 8. 정확도(Accuracy) 계산  \n",
    "🔧 실습 문제 9  \n",
    "모델이 얼마나 잘 맞췄는지 정확도를 직접 계산하는 함수를 작성하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd1cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.58%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # 평가 모드로 전환\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # 기울기 계산 비활성화\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "acc = evaluate_model(model, test_loader)\n",
    "print(f'Accuracy: {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa821ee",
   "metadata": {},
   "source": [
    "\n",
    "### Part 9. 학습 과정 시각화  \n",
    "🔧 실습 문제 10  \n",
    "에폭별 손실값을 저장하고 `matplotlib`을 이용해 학습 곡선을 시각화하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28adaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5001\n",
      "Epoch 2, Loss: 0.3942\n",
      "Epoch 3, Loss: 0.3528\n",
      "Epoch 4, Loss: 0.3283\n",
      "Epoch 5, Loss: 0.3106\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = MyNet()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1} Loss: {avg_loss:.4f}\")\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"학습 손실 곡선\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81df2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "images, labels = next(iter(test_loader))\n",
    "images, labels = images[:10], labels[:10]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "    plt.title(f\"예측: {preds[i].item()} / 실제: {labels[i].item()}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab27a56c",
   "metadata": {},
   "source": [
    "\n",
    "## 🎁 보너스 미션  \n",
    "- `nn.Module`과 `nn.Sequential` 방식의 모델을 비교  \n",
    "- 옵티마이저를 Adam으로 바꾸고 학습 결과 비교  \n",
    "- 은닉층 크기를 256으로 변경하여 과적합 여부 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0634b",
   "metadata": {},
   "source": [
    "## 🎯 보너스 문제 1: `nn.Module` vs `nn.Sequential` 모델을 예시를 들어 비교하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")\n",
    "optimizer_seq = torch.optim.SGD(model_seq.parameters(), lr=0.01)\n",
    "train_model(model_seq, train_loader, criterion, optimizer_seq)\n",
    "acc_seq = evaluate_accuracy(model_seq, test_loader)\n",
    "\n",
    "model_module = MyNet()\n",
    "optimizer_module = torch.optim.SGD(model_module.parameters(), lr=0.01)\n",
    "train_model(model_module, train_loader, criterion, optimizer_module)\n",
    "acc_module = evaluate_accuracy(model_module, test_loader)\n",
    "\n",
    "print(f\"정확도 (nn.Module): {acc_module:.4f}\")\n",
    "print(f\"정확도 (nn.Sequential): {acc_seq:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6669af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f20a782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e56e02e0",
   "metadata": {},
   "source": [
    "## 🎯 보너스 문제 2: Optimizer SGD vs Adam 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e070bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    return MyNet()\n",
    "\n",
    "# SGD Optimizer\n",
    "model_sgd = create_model()\n",
    "optimizer_sgd = torch.optim.SGD(model_sgd.parameters(), lr=0.01)\n",
    "train_model(model_sgd, train_loader, criterion, optimizer_sgd)\n",
    "acc_sgd = evaluate_accuracy(model_sgd, test_loader)\n",
    "\n",
    "# Adam Optimizer\n",
    "model_adam = create_model()\n",
    "optimizer_adam = torch.optim.Adam(model_adam.parameters(), lr=0.001)\n",
    "train_model(model_adam, train_loader, criterion, optimizer_adam)\n",
    "acc_adam = evaluate_accuracy(model_adam, test_loader)\n",
    "\n",
    "print(f\"정확도 (SGD): {acc_sgd:.4f}\")\n",
    "print(f\"정확도 (Adam): {acc_adam:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cbd191",
   "metadata": {},
   "source": [
    "## 🎯 보너스 문제 3: 은닉층 크기 변경 (128 → 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be754ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet256(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model_128 = MyNet()\n",
    "optimizer_128 = torch.optim.SGD(model_128.parameters(), lr=0.01)\n",
    "train_model(model_128, train_loader, criterion, optimizer_128)\n",
    "acc_128 = evaluate_accuracy(model_128, test_loader)\n",
    "\n",
    "model_256 = MyNet256()\n",
    "optimizer_256 = torch.optim.SGD(model_256.parameters(), lr=0.01)\n",
    "train_model(model_256, train_loader, criterion, optimizer_256)\n",
    "acc_256 = evaluate_accuracy(model_256, test_loader)\n",
    "\n",
    "print(f\"정확도 (128개 은닉층): {acc_128:.4f}\")\n",
    "print(f\"정확도 (256개 은닉층): {acc_256:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
