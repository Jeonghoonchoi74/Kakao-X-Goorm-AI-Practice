{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b44ce00c",
   "metadata": {},
   "source": [
    "# 🚩 문제지 (Mission Brief)\n",
    "\n",
    "## 🏕️ 스토리: “캠핑 마스터 AI”\n",
    "국내 최대 아웃도어 기업 **캠핑 마스터**는 △장비 추천 챗봇 △캠핑장 리뷰 분석 △사전 안전 점검 알람 등을 제공하는 **통합 AI 어시스턴트**를 출시하려 합니다. 여러분은 막 입사한 **NLP 엔지니어**로서, 다음 네 단계의 모듈을 순차적으로 구축‧실험해야 합니다.\n",
    "\n",
    "각 단계의 **starter code**는 50 % 이상 완성돼 있으니, `### TODO` 표시 부분만 채워서 실행·검증하세요.\n",
    "\n",
    "> **환경 준비** (필수)  \n",
    "> ```bash\n",
    "> pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "> pip install datasets transformers accelerate seqeval\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fddac65",
   "metadata": {},
   "source": [
    "### 과제 1 (의도 분류 GRU)  \n",
    "**목표** : 사용자의 자연어 요청을 150 개 의도로 분류해 챗봇 라우팅 성능을 평가한다.  \n",
    "**데이터** : Hugging Face → `clinc_oos`, config `\"small\"`  \n",
    "\n",
    "```python\n",
    "from datasets import load_dataset\n",
    "raw = load_dataset(\"clinc_oos\", \"small\")\n",
    "print(raw[\"train\"][0])\n",
    "```\n",
    "#### Starter Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac3c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "MAX_LEN, BATCH = 32, 64\n",
    "tok = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "pad_id = tok.pad_token_id\n",
    "\n",
    "def tokenize(b):\n",
    "    return tok(b[\"text\"], padding=\"max_length\",\n",
    "               truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "ds = load_dataset(\"clinc_oos\", \"small\")\n",
    "\n",
    "# 컬럼명 intent → labels\n",
    "ds = ds.rename_column(\"intent\", \"labels\")\n",
    "\n",
    "# 토크나이즈\n",
    "ds = ds.map(tokenize, batched=True)\n",
    "\n",
    "# Torch 텐서 형식으로 지정\n",
    "ds.set_format(type=\"torch\",\n",
    "              columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "train_dl = DataLoader(ds[\"train\"], batch_size=BATCH, shuffle=True)\n",
    "test_dl  = DataLoader(ds[\"test\"],  batch_size=BATCH)\n",
    "\n",
    "\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, vocab, embed_dim, hidden, num_labels):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab, embed_dim, padding_idx=tokenizer.pad_token_id)\n",
    "        self.gru   = nn.GRU(embed_dim, hidden, batch_first=True, bidirectional=True)\n",
    "        self.fc    = nn.Linear(hidden*2, num_labels)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        x = self.embed(ids)\n",
    "        x, _ = self.gru(x)\n",
    "        x = torch.cat([x[:,0,:hidden], x[:,-1,hidden:]], dim=-1)  # 양방향 첫·끝 스텝 결합\n",
    "        return self.fc(x)\n",
    "\n",
    "### TODO 1-a : 임베딩 차원, hidden size 등 하이퍼파라미터 지정\n",
    "### TODO 1-b : 훈련 루프(optimizer, loss 정의 및 epoch 반복) 작성\n",
    "### TODO 1-c : 테스트 셋 정확도 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a988e7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d16e93b5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 과제 2 (BiLSTM + CRF NE 인식)  \n",
    "**목표** : 캠핑 준비물 체크리스트에서 **장비·지역·날짜** 등 엔티티를 추출한다.  \n",
    "**데이터** : `conll2003` (영문) – 실제 캠핑 도메인과 다르지만, 모델 아키텍처 학습용으로 사용.  \n",
    "\n",
    "> CRF 계층 구현이 부담스러우면, `seqeval` 평가 지표와 **BiLSTM+Linear** 구조만 완성해도 통과점수를 얻을 수 있다.\n",
    "\n",
    "```python\n",
    "# 데이터 예시\n",
    "from datasets import load_dataset\n",
    "ner = load_dataset(\"conll2003\")\n",
    "print(ner[\"train\"][0])\n",
    "```\n",
    "#### Starter Code (BiLSTM Tagger skeleton)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02804cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMTagger(nn.Module):\n",
    "    def __init__(self, vocab, tagset, embed_dim=100, hidden=256):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab, embed_dim)\n",
    "        self.lstm  = nn.LSTM(embed_dim, hidden, num_layers=1,\n",
    "                             batch_first=True, bidirectional=True)\n",
    "        self.fc    = nn.Linear(hidden*2, tagset)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        em = self.embed(ids)\n",
    "        out, _ = self.lstm(em)\n",
    "        return self.fc(out)          # [batch, seq, tag]\n",
    "\n",
    "### TODO 2-a : 토크나이저를 훈련 셋 vocab 으로 학습\n",
    "### TODO 2-b : padding & masking 함수 구현\n",
    "### TODO 2-c : CrossEntropyLoss(ignore_index=pad_tag) 로 모델 학습\n",
    "### TODO 2-d : seqeval (f1) 로 성능 측정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ccac04",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 과제 3 (1D CNN 리뷰 감성 분류)  \n",
    "**목표** : 캠핑장 리뷰를 긍정/부정으로 분류하여 별점 이상/이하를 탐지한다.  \n",
    "**데이터** : Hugging Face → `imdb` (binary sentiment)\n",
    "\n",
    "#### Starter Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be6d634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab, embed_dim=128, num_classes=2, k=[3,4,5]):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab, embed_dim, padding_idx=tokenizer.pad_token_id)\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Conv1d(embed_dim, 100, kernel_size=ks) for ks in k])\n",
    "        self.fc = nn.Linear(100*len(k), num_classes)\n",
    "\n",
    "    def forward(self, ids):\n",
    "        x = self.embed(ids).transpose(1,2)                # [B,C,L]\n",
    "        x = torch.cat([torch.relu(c(x)).max(2)[0] for c in self.convs], 1)\n",
    "        return self.fc(x)\n",
    "\n",
    "### TODO 3-a : 토큰화·DataLoader 작성\n",
    "### TODO 3-b : 훈련 루프 및 정확도 평가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d26e9",
   "metadata": {},
   "source": [
    "## 데이터셋 다운로드 요약\n",
    "\n",
    "| 과제 | 데이터셋 (🤗 Datasets) | 호출 예시 |\n",
    "|------|-----------------------|-----------|\n",
    "| 1 | `clinc_oos`, `\"small\"` | `load_dataset(\"clinc_oos\",\"small\")` |\n",
    "| 2 | `conll2003` | `load_dataset(\"conll2003\")` |\n",
    "| 3 | `imdb` | `load_dataset(\"imdb\")` |\n",
    "| 4 | `daily_dialog` | `load_dataset(\"daily_dialog\")` |\n",
    "\n",
    "### 마무리 팁\n",
    "- 각 과제 스크립트는 `torch.save(model.state_dict(), \"...\")`로 체크포인트를 저장해두면, 후속 실험(하이퍼파라미터 튜닝, 앙상블) 시 시간을 절약할 수 있습니다.  \n",
    "- CPU 에서 빠르게 실습하려면 `datasets` 의 `.select(range(N))`로 샘플 수를 줄여 디버깅 후, GPU 훈련 환경에서 전체 데이터로 재훈련하세요.\n",
    "\n",
    "성공적인 **캠핑 마스터 AI** 출시를 기원합니다! 🏕️"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
